# Request for Comments (RFC): Albion Market Ingestor & API

## 1. Цель проекта
Создать надежный сервис агрегации рыночных цен Albion Online с упором на ресурсы и "ходовые" предметы для расчета прибыльности крафта. Система должна работать автономно 24/7.

## 2. Основные компоненты системы

### 2.1. Database (PostgreSQL 16+)
* **Роль:** Единый источник правды.
* **Схема:** Управление через Alembic.
* **Политика хранения данных (Data Retention):**
    * **Raw Data (Сырые данные):** Хранятся 30 дней (полная детализация по времени загрузки).
    * **Historical Data (Архив):** Данные старше 30 дней подвергаются "сжатию" (Downsampling). Рассчитывается средняя цена (Average) за сутки (или 6-часовые интервалы). Сырые данные удаляются.

### 2.2. Ingestion Service (Worker)
* **Роль:** Фоновый процесс сбора данных.
* **Технология:** Python (отдельный контейнер).
* **Принцип работы:**
    1.  Получает задачи из таблицы `tracked_items` (активные предметы в конкретных городах).
    2.  Группирует запросы (Batching) по 50-100 предметов для одного города.
    3.  Запрашивает данные у Albion Data Project API.
    4.  Сохраняет текущие цены (`market_prices`) и историю (`market_history`).
    5.  Обновляет время проверки (`last_check`).

### 2.3. Backend API
* **Роль:** Предоставление данных для Frontend/UI.
* **Технология:** FastAPI.
* **Безопасность:** Доступ к БД только внутри Docker-сети.

## 3. Ключевые архитектурные решения

### 3.1. Управление очередью (Tracked Items)
* Парсинг управляется через БД. Таблица `tracked_items` содержит составной ключ `(item_id, location_id)`.
* Это позволяет точечно настраивать, какие предметы в каких городах мониторить, избегая загрузки лишних данных.

### 3.2. Отказоустойчивость
* Использование паттерна **Exponential Backoff** при ошибках сети или 5xx кодах от API Альбиона.
* Воркер не должен падать; он должен логировать ошибку и ждать перед повтором.